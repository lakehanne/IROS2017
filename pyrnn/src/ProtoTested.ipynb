{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Epoch [1/500], Loss: inf\n",
      "Epoch [11/500], Loss: nan\n",
      "Epoch [21/500], Loss: nan\n",
      "Epoch [31/500], Loss: nan\n",
      "Epoch [41/500], Loss: nan\n",
      "Epoch [51/500], Loss: nan\n",
      "Epoch [61/500], Loss: nan\n",
      "Epoch [71/500], Loss: nan\n",
      "Epoch [81/500], Loss: nan\n",
      "Epoch [91/500], Loss: nan\n",
      "Epoch [101/500], Loss: nan\n",
      "Epoch [111/500], Loss: nan\n",
      "Epoch [121/500], Loss: nan\n",
      "Epoch [131/500], Loss: nan\n",
      "Epoch [141/500], Loss: nan\n",
      "Epoch [151/500], Loss: nan\n",
      "Epoch [161/500], Loss: nan\n",
      "Epoch [171/500], Loss: nan\n",
      "Epoch [181/500], Loss: nan\n",
      "Epoch [191/500], Loss: nan\n",
      "Epoch [201/500], Loss: nan\n",
      "Epoch [211/500], Loss: nan\n",
      "Epoch [221/500], Loss: nan\n",
      "Epoch [231/500], Loss: nan\n",
      "Epoch [241/500], Loss: nan\n",
      "Epoch [251/500], Loss: nan\n",
      "Epoch [261/500], Loss: nan\n",
      "Epoch [271/500], Loss: nan\n",
      "Epoch [281/500], Loss: nan\n",
      "Epoch [291/500], Loss: nan\n",
      "Epoch [301/500], Loss: nan\n",
      "Epoch [311/500], Loss: nan\n",
      "Epoch [321/500], Loss: nan\n",
      "Epoch [331/500], Loss: nan\n",
      "Epoch [341/500], Loss: nan\n",
      "Epoch [351/500], Loss: nan\n",
      "Epoch [361/500], Loss: nan\n",
      "Epoch [371/500], Loss: nan\n",
      "Epoch [381/500], Loss: nan\n",
      "Epoch [391/500], Loss: nan\n",
      "Epoch [401/500], Loss: nan\n",
      "Epoch [411/500], Loss: nan\n",
      "Epoch [421/500], Loss: nan\n",
      "Epoch [431/500], Loss: nan\n",
      "Epoch [441/500], Loss: nan\n",
      "Epoch [451/500], Loss: nan\n",
      "Epoch [461/500], Loss: nan\n",
      "Epoch [471/500], Loss: nan\n",
      "Epoch [481/500], Loss: nan\n",
      "Epoch [491/500], Loss: nan\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import torch.cuda\n",
    "import numpy as np\n",
    "\n",
    "from qpth.qp import QPFunction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    '''\n",
    "    nn.LSTM Parameters:\n",
    "        input_size  – The number of expected features in the input x\n",
    "        hidden_size – The number of features in the hidden state h\n",
    "        num_layers  – Number of recurrent layers.\n",
    "\n",
    "    Inputs: input, (h_0, c_0)\n",
    "        input (seq_len, batch, input_size)\n",
    "        h_0 (num_layers * num_directions, batch, hidden_size)\n",
    "        c_0 (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "    Outputs: output, (h_n, c_n)\n",
    "        output (seq_len, batch, hidden_size * num_directions)\n",
    "        h_n (num_layers * num_directions, batch, hidden_size)\n",
    "        c_n (num_layers * num_directions, batch, hidden_size):\n",
    "    '''\n",
    "    def __init__(self, inputSize, nHidden, batchSize, noutputs=3, numLayers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.cost = nn.MSELoss(size_average=False)\n",
    "        self.noutputs = noutputs\n",
    "        self.num_layers = numLayers\n",
    "        self.inputSize = inputSize\n",
    "        self.nHidden = nHidden\n",
    "        self.batchSize = batchSize\n",
    "        self.noutputs = noutputs\n",
    "        \n",
    "        #define recurrent and linear layers\n",
    "        self.lstm1  = nn.LSTM(inputSize,nHidden[0],num_layers=numLayers)\n",
    "        self.lstm2  = nn.LSTM(nHidden[0],nHidden[1],num_layers=numLayers)\n",
    "        self.lstm3  = nn.LSTM(nHidden[1],nHidden[2],num_layers=numLayers)\n",
    "        self.fc     = nn.Linear(nHidden[2], noutputs)\n",
    "        self.drop   = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.Tensor(self.num_layers, batchSize, self.nHidden[0])) \n",
    "        c0 = Variable(torch.Tensor(self.num_layers, batchSize, self.nHidden[0]))        \n",
    "        # Forward propagate RNN layer 1\n",
    "        out, _ = self.lstm1(x, (h0, c0)) \n",
    "        out = self.drop(out)\n",
    "        \n",
    "        # Set hidden layer 2 states \n",
    "        h1 = Variable(torch.Tensor(self.num_layers, batchSize, self.nHidden[1])) \n",
    "        c1 = Variable(torch.Tensor(self.num_layers, batchSize, self.nHidden[1]))        \n",
    "        # Forward propagate RNN layer 2\n",
    "        out, _ = self.lstm2(out, (h1, c1))  \n",
    "        \n",
    "        # Set hidden layer 3 states \n",
    "        h2 = Variable(torch.Tensor(self.num_layers, batchSize, self.nHidden[2])) \n",
    "        c2 = Variable(torch.Tensor(self.num_layers, batchSize, self.nHidden[2]))        \n",
    "        # Forward propagate RNN layer 2\n",
    "        out, _ = self.lstm3(out, (h2, c2)) \n",
    "        out = self.drop(out) \n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "#hyperparams\n",
    "inputSize = 9\n",
    "nHidden   = [9,6,6]\n",
    "numLayers = 2\n",
    "sequence_length = 9\n",
    "num_epochs = 500\n",
    "noutputs = 3\n",
    "batchSize = 1\n",
    "\n",
    "lstm = LSTMModel(inputSize, nHidden, batchSize, noutputs, numLayers)\n",
    "#lstm.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr=0.1)\n",
    "\n",
    "#images and labels\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = Variable(torch.Tensor(5, 1, 9))\n",
    "    labels = Variable(torch.Tensor(5, 3))\n",
    "\n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()\n",
    "    outputs = lstm(inputs)\n",
    "    loss    = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch % 10) == 0:\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('output, hn', Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.0594 -0.0667  0.1891 -0.1240  0.2621 -0.1618  0.1374  0.2346  0.1203\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.0041 -0.0961  0.0826 -0.1564  0.1250 -0.2096 -0.0419  0.2256  0.0997\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.0424 -0.0660  0.0180 -0.0556  0.0714 -0.2139 -0.1316  0.1229  0.0921\n",
      "\n",
      "(3 ,.,.) = \n",
      " -0.0292 -0.0185  0.0154  0.0144  0.0572 -0.1743 -0.1293  0.0378  0.0829\n",
      "\n",
      "(4 ,.,.) = \n",
      "  0.0014 -0.0254 -0.0038  0.0402  0.0844 -0.1310 -0.1433  0.0125  0.1028\n",
      "[torch.FloatTensor of size 5x1x9]\n",
      ", (Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1835 -0.1025  0.1177  0.0033 -0.0459  0.1522  0.1153 -0.0820  0.1727\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.0014 -0.0254 -0.0038  0.0402  0.0844 -0.1310 -0.1433  0.0125  0.1028\n",
      "[torch.FloatTensor of size 2x1x9]\n",
      ", Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.4481 -0.1853  0.2029  0.0166 -0.1076  0.4126  0.2311 -0.3411  0.3912\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.0026 -0.0725 -0.0071  0.0987  0.1633 -0.2757 -0.4131  0.0285  0.2453\n",
      "[torch.FloatTensor of size 2x1x9]\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nn.LSTM Parameters:\n",
    "    input_size  – The number of expected features in the input x\n",
    "    hidden_size – The number of features in the hidden state h\n",
    "    num_layers  – Number of recurrent layers.\n",
    "    \n",
    "Inputs: input, (h_0, c_0)\n",
    "    input (seq_len, batch, input_size)\n",
    "    h_0 (num_layers * num_directions, batch, hidden_size)\n",
    "    c_0 (num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "Outputs: output, (h_n, c_n)\n",
    "    output (seq_len, batch, hidden_size * num_directions)\n",
    "    h_n (num_layers * num_directions, batch, hidden_size)\n",
    "    c_n (num_layers * num_directions, batch, hidden_size):\n",
    "'''\n",
    "rnnp = nn.LSTM(9, 9, 2)\n",
    "inputp = Variable(torch.randn(5,1, 9))\n",
    "h0p = Variable(torch.randn(2, 1, 9))\n",
    "c0p = Variable(torch.randn(2, 1, 9))\n",
    "outputp, hnp = rnnp(inputp, (h0p, c0p))\n",
    "print('output, hn', outputp, hnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.5428  1.4186  1.8866  0.8649  0.6995  0.3084  0.9364 -0.2720  1.5090\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.5815  0.3990  1.5051 -0.1367 -0.7284 -0.8908  0.4778  0.1386 -0.4370\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.6140 -0.2190  1.1750  1.1742  0.9553 -1.0940  1.0156  0.4339  0.3522\n",
      "\n",
      "(3 ,.,.) = \n",
      " -0.2989  0.3756 -0.5670  0.8080 -1.9982  0.9758  2.0426  2.8202 -0.4405\n",
      "\n",
      "(4 ,.,.) = \n",
      "  2.0539 -0.1440 -0.2703 -1.1998  0.0871  0.3628  0.2336  2.0507  0.9338\n",
      "[torch.FloatTensor of size 5x1x9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "print inputp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  5.5608e+31  4.5883e-41  5.5608e+31  4.5883e-41  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  1.5695e-43\n",
       "\n",
       "(1 ,.,.) = \n",
       "  5.5608e+31  4.5883e-41  5.5608e+31  4.5883e-41  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  1.5695e-43\n",
       "\n",
       "(2 ,.,.) = \n",
       "  5.5608e+31  4.5883e-41  5.5608e+31  4.5883e-41  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  1.5695e-43\n",
       "\n",
       "(3 ,.,.) = \n",
       "  5.5608e+31  4.5883e-41  5.5608e+31  4.5883e-41  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  1.5695e-43\n",
       "\n",
       "(4 ,.,.) = \n",
       "  5.5608e+31  4.5883e-41  5.5608e+31  4.5883e-41  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
       "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  1.5695e-43\n",
       "[torch.FloatTensor of size 5x5x5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cpu()\n",
    "x.unsqueeze(0).expand(*([5]+list(x.size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1122e+31\n",
       " 5.1643e+23\n",
       " 1.0329e+24\n",
       " 5.1643e+23\n",
       " 1.0329e+24\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5,5)\n",
    "print x.ndimension()\n",
    "x.mean(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
