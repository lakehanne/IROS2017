{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSavedMatFile(x):\n",
    "\tdata = sio.loadmat(x)\n",
    "\t# populate each column of array \t#convert from numpy to torchTensor\n",
    "\tbase_in   = Variable(torch.from_numpy(data['base_in']))\n",
    "\tbase_out  = Variable(torch.from_numpy(data['base_out']))\n",
    "\tleft_in   = Variable(torch.from_numpy(data['left_in']))\n",
    "\tleft_out  = Variable(torch.from_numpy(data['left_out']))\n",
    "\tright_in  = Variable(torch.from_numpy(data['right_out']))\n",
    "\tright_out = Variable(torch.from_numpy(data['right_out']))\n",
    "\tx     \t  = Variable(torch.from_numpy(data['x']))\n",
    "\ty     \t  = Variable(torch.from_numpy(data['y']))\n",
    "\tz     \t  = Variable(torch.from_numpy(data['z']))\n",
    "\tpitch     = Variable(torch.from_numpy(data['pitch']))\n",
    "\tyaw   \t  = Variable(torch.from_numpy(data['yaw']))\n",
    "\n",
    "\treturn \tbase_in, base_out, left_in, left_out, right_in, right_out, x, y, z, pitch, yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tbase_in, base_out, left_in, left_out, right_in, right_out, x, y, z, pitch, yaw = loadSavedMatFile(\"data/data.mat\")\n",
    "\tinputs = torch.cat((base_in, base_out, left_in, \n",
    "\t\t\t\t\t\tleft_out, right_in, right_out, \n",
    "\t\t\t\t\t\tz, pitch, yaw), 1)\n",
    "\toutputs = torch.cat((z, pitch, yaw), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\tN = int(inputs.size(0))\n",
    "\n",
    "\tnTrain = int(N*(1.-0.1))\n",
    "\tnTest  = N - nTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\ttrain_in = inputs[:nTrain]\n",
    "\ttrain_out = outputs[:nTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "fields = ['epoch', 'loss', 'err']\n",
    "trainF = open(os.path.join('save', 'train.csv'), 'w')\n",
    "trainW = csv.writer(trainF)\n",
    "trainW.writerow(fields)\n",
    "trainF.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = ['epoch', 'loss', 'err']\n",
    "testF = open(os.path.join('save', 'test.csv'), 'w')\n",
    "testW = csv.writer(testF)\n",
    "testW.writerow(fields)\n",
    "testF.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x):\n",
    "\tbase_in, base_out, left_in, left_out, right_in, right_out, x, y, z, pitch, yaw = loadSavedMatFile(x)\n",
    "\tinputs = torch.cat((base_in, base_out, left_in, \n",
    "\t\t\t\t\t\tleft_out, right_in, right_out, \n",
    "\t\t\t\t\t\tz, pitch, yaw), 1)\n",
    "\toutputs = torch.cat((z, pitch, yaw), 1)\n",
    "\n",
    "\tN = int(inputs.size(0))\n",
    "\n",
    "\tnTrain = int(N*(1.-0.1))\n",
    "\tnTest  = N - nTrain\n",
    "\t# print('outputs: \\n', base_in[0:int(k)])\n",
    "\ttrain_in = inputs[:nTrain]\n",
    "\ttrain_out = outputs[:nTrain]\n",
    "\ttest_in = inputs[nTrain:]\n",
    "\ttest_out = inputs[nTrain:]\n",
    "\n",
    "\tbase_idx = torch.LongTensor([1])\n",
    "\t# print(inputs.narrow(0, 0, base_in.size(0)))\n",
    "\n",
    "\treturn train_in, train_out, test_in, test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = split_data(\"data/data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "\n",
    "batch_data_t = torch.FloatTensor(batchSize, trainX.size(1))\n",
    "batch_targets_t = torch.FloatTensor(batchSize, trainY.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3a231f175748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_data_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_targets_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_targets_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/robotec/anaconda2/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/robotec/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/robotec/anaconda2/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m     96\u001b[0m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_data_t = batch_data_t.cuda()\n",
    "batch_targets_t = batch_targets_t.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = Variable(batch_data_t, requires_grad=False)\n",
    "batch_targets = Variable(batch_targets_t, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size at /home/lex/Documents/NNs/locuslab-pytorch/torch/lib/TH/generic/THTensorCopy.c:52",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3201525f99cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbatchSz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatchSz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#batch_targets.data[:] = trainY[i:i+batchSz]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lex/anaconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mSetItem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mSetItem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lex/anaconda2/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i, value)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size at /home/lex/Documents/NNs/locuslab-pytorch/torch/lib/TH/generic/THTensorCopy.c:52"
     ]
    }
   ],
   "source": [
    "batchSize = 50\n",
    "batch_data_t = torch.DoubleTensor(batchSize, trainX.size(1))\n",
    "batch_targets_t = torch.DoubleTensor(batchSize, trainY.size(1))\n",
    "\n",
    "batch_data = Variable(batch_data_t, requires_grad=False)\n",
    "batch_targets = Variable(batch_targets_t, requires_grad=False)\n",
    "\n",
    "batchSz = batchSize\n",
    "print batchSz\n",
    "for i in range(0, trainX.size(0), batchSz):\n",
    "\tbatch_data[:] = trainX[i:i+batchSz]\n",
    "\t#batch_targets.data[:] = trainY[i:i+batchSz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 50\n",
    "batch_data_t = torch.DoubleTensor(batchSize, trainX.size(1))\n",
    "batch_targets_t = torch.DoubleTensor(batchSize,\n",
    "\n",
    "batch_data = Variable(batch_data_t, requires_grad=False)\n",
    "batch_targets = Variable(batch_targets_t, requires_grad=False)\n",
    "\n",
    "for i in range(0, trainX.size(0), batchSz):\n",
    "\tbatch_data.data[:] = trainX[i:i+batchSz]\n",
    "\tbatch_targets.data[:] = trainY[i:i+batchSz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_data_t = torch.DoubleTensor(batchSize, trainX.size(1))\n",
    "batch_data_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = Variable(batch_data_t, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_data[:] = trainX.data[0:0+batchSz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, trainX.size(0), batchSz):\n",
    "\tbatch_data[:] = trainX.data[i:i+batchSz]\n",
    "\tbatch_targets[:] = trainY.data[i:i+batchSz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nUnexpected input: Expected a non-empty list of lists.\nIf you are interested in helping expand the functionality\nfor your use case please send in an issue or PR at\nhttp://github.com/bamos/block",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7027248189a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m K = block((\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left_in'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left_out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;31m#(data['right_in']), (data['right_out'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         ))\n",
      "\u001b[0;32m/home/lex/anaconda2/lib/python2.7/site-packages/block/block.pyc\u001b[0m in \u001b[0;36mblock\u001b[0;34m(rows, dtype, arrtype)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0minterested\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhelping\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunctionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myour\u001b[0m \u001b[0muse\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mplease\u001b[0m \u001b[0msend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0man\u001b[0m \u001b[0missue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mPR\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m http://github.com/bamos/block''')\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrowLens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nUnexpected input: Expected a non-empty list of lists.\nIf you are interested in helping expand the functionality\nfor your use case please send in an issue or PR at\nhttp://github.com/bamos/block"
     ]
    }
   ],
   "source": [
    "data = sio.loadmat(\"data/data.mat\")\n",
    "from block import block\n",
    "K = block((\n",
    "            (data['base_in']), (data['base_out']),\n",
    "            (data['left_in']), (data['left_out']),\n",
    "            (data['right_in']), (data['right_out'])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sio.loadmat(\"data/data.mat\")\n",
    "import numpy as np\n",
    "K = np.bmat((\n",
    "            (data['base_in']), (data['base_out']),\n",
    "            (data['left_in']), (data['left_out']),\n",
    "            (data['right_in']), (data['right_out'])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import model\n",
    "nFeatures, nCls, nHidden = 6, 3, [9,6,6]\n",
    "net = model.LSTMModel(nFeatures, nCls, nHidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 100, 3])\n"
     ]
    }
   ],
   "source": [
    "X = Variable(torch.randn(5, 100, 3).type(torch.cuda.FloatTensor), requires_grad=False)\n",
    "print x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import numpy.testing as npt\n",
    "# import numdifftools as nd\n",
    "import cvxpy as cp\n",
    "\n",
    "# import adact\n",
    "# import adact_forward_ip as aip\n",
    "\n",
    "npr.seed(1)\n",
    "nz, neq, nineq = 5, 0, 4\n",
    "\n",
    "L = np.tril(npr.randn(nz,nz)) + 2.*np.eye(nz,nz)\n",
    "Q = L.dot(L.T)+1e-8*np.eye(nz)\n",
    "G = 1000.*npr.randn(nineq,nz)\n",
    "A = 10000.*npr.randn(neq,nz)\n",
    "z0 = 1.*npr.randn(nz)\n",
    "s0 = 100.*np.ones(nineq)\n",
    "\n",
    "p = npr.randn(nz)\n",
    "\n",
    "p_t, Q_t, G_t, A_t, z0_t, s0_t = [torch.Tensor(x) for x in [p, Q, G, A, z0, s0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0 4\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print nz,neq, nineq\n",
    "# print  p_t, Q_t, G_t, A_t, z0_t, s0_t\n",
    "t = '{}.{}'.format(2, 'optNET')\n",
    "t += '.Qpenalty={}'.format(0.1)\n",
    "print A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1  2  3\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1  2  3\n",
      "\n",
      "(2 ,.,.) = \n",
      "  1  2  3\n",
      "\n",
      "(3 ,.,.) = \n",
      "  1  2  3\n",
      "\n",
      "(4 ,.,.) = \n",
      "  1  2  3\n",
      "[torch.FloatTensor of size 5x1x3]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "L = Parameter(torch.tril(torch.rand(2, 2)))\n",
    "M = Variable(torch.tril(torch.ones(2, 2)))\n",
    "L = M*L\n",
    "Q = L.mm(L.t()) + 0.001 * Variable(torch.eye(2))\n",
    "Q = Q.unsqueeze(0).expand(5,2,2)\n",
    "G = Parameter(torch.Tensor(4,2).uniform_(-1,1))\n",
    "G = G.unsqueeze(0).expand(5, 4, 2)\n",
    "x = torch.Tensor(5, 1, 9)\n",
    "\n",
    "#-------------------------------------------------------------#\n",
    "nz = 3\n",
    "nx = nz * 2\n",
    "nHidden = 9\n",
    "nBatch = 5\n",
    "nineq = 12\n",
    "neq = 0\n",
    "\n",
    "A = Parameter(torch.randn(neq, nx).double())\n",
    "h = Variable(torch.ones(nx).double())\n",
    "G = torch.eye(nineq, 3).double()\n",
    "for i in range(nz):\n",
    "    G[i][i] *= -1\n",
    "q = torch.DoubleTensor(2).cuda()\n",
    "e = Variable(torch.Tensor().double())\n",
    "version = torch.__version__\n",
    "\n",
    "targ = torch.Tensor([[1, 2, 3]])\n",
    "targ = Variable(targ.expand_as(torch.LongTensor(5, 1, 3)))\n",
    "print(targ)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
